{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globus and funcX \n",
    "\n",
    "Using Globus and funcX to automate the process of uploading data to NeSI, running a Slurm job on NeSI and then copying results back.\n",
    "\n",
    "This will demonstrate:\n",
    "\n",
    "* Globus and funcX Python packages\n",
    "* Doing Globus authentication use the fair_research_login module\n",
    "* Uploading and downloading files to a shared collection using https (no personal endpoint required)\n",
    "* Running funcX functions to submit and wait for a Slurm job on the remote machine\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* Globus account\n",
    "* NeSI account\n",
    "\n",
    "Setup Steps:\n",
    "\n",
    "1. Start a FuncX endpoint on NeSI (via SSH or Jupyter)\n",
    "2. Create a Globus guest collection on NeSI (via Globus web app)\n",
    "3. Globus authentication on local machine\n",
    "4. Start funcX client locally\n",
    "5. Connect to our Globus guest connection on NeSI\n",
    "6. Configure HTTPS uploads/downloads for our NeSI guest collection\n",
    "7. Create remote directory using funcX\n",
    "\n",
    "Processing Steps:\n",
    "\n",
    "8. Transfer input data to NeSI using Globus\n",
    "9. Run the workflow using funcX\n",
    "10. Copy results back using Globus\n",
    "\n",
    "The tokens generated during step 3 on the local machine are stored in a file and reused, so you should only need to authenticate the first time you run this notebook.\n",
    "\n",
    "References:\n",
    "\n",
    "* [Globus tutorial](https://globus-sdk-python.readthedocs.io/en/stable/tutorial.html)\n",
    "* [funcX endpoint documentation](https://funcx.readthedocs.io/en/latest/endpoints.html)\n",
    "* [fair-research-login](https://github.com/fair-research/native-login)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Start a funcX endpoint on NeSI\n",
    "\n",
    "### Install and configure funcX endpoint if you have not done it before\n",
    "\n",
    "Connect to a Mahuika login node by SSH and run the following commands to install funcX:\n",
    "\n",
    "```sh\n",
    "ssh mahuika\n",
    "module load funcx-endpoint\n",
    "funcx-endpoint configure\n",
    "```\n",
    "\n",
    "During the final command you will be asked to authenticate with Globus Auth so that your endpoint can be made available to funcX running outside of NeSI.\n",
    "\n",
    "For more details see: https://funcx.readthedocs.io/en/latest/endpoints.html.\n",
    "\n",
    "### Start the funcx endpoint on NeSI\n",
    "\n",
    "A default endpoint profile is created during the configure step above, which will suffice for us. We will be using funcx to submit jobs to Slurm or check the status of submitted jobs; no computationally expensive tasks should run directly on the endpoint itself.\n",
    "\n",
    "```sh\n",
    "# we are still on the Mahuika login node here...\n",
    "funcx-endpoint start\n",
    "```\n",
    "\n",
    "Now list your endpoints, confirm that the *default* endpoint is \"Running\" and make a note of your endpoint ID:\n",
    "\n",
    "```sh\n",
    "funcx-endpoint list\n",
    "+---------------+-----------+--------------------------------------+\n",
    "| Endpoint Name | Status    |             Endpoint ID              |\n",
    "+===============+===========+======================================+\n",
    "| default       | Running   | ffd77d5c-b65f-4479-bbc3-66a2f7346858 |\n",
    "+---------------+-----------+--------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store your funcx endpoint id here\n",
    "funcx_endpoint = \"ffd77d5c-b65f-4479-bbc3-66a2f7346858\"  # my default endpoint on NeSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Globus guest collection on NeSI\n",
    "\n",
    "Create a guest collection on the NeSI endpoint, so that we don't need to do the NeSI two factor authentication repeatedly, we can just use Globus auth.\n",
    "\n",
    "Navigate to a directory under */nesi/nobackup/[project_code]/*, click sharing and add a shared collection. Make a note of the \"Endpoint UUID\". Also store the full path on NeSI to the shared collection you just created (`nesi_path`):\n",
    "\n",
    "https://transfer.nesi.org.nz/file-manager?origin_id=cc45cfe3-21ae-4e31-bad4-5b3e7d6a2ca1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store your NeSI endpoint and path here\n",
    "nesi_endpoint = \"3999b2ad-d708-4b0e-9f4d-8f90838c7f23\"  # my guest collection on NeSI\n",
    "nesi_path = \"/nesi/nobackup/nesi99999/csco212/rjm\"  # the full path to where I created the guest collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Globus authentication on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register an app with Globus, if you haven't done it already\n",
    "\n",
    "Note: I think this is a one off, you can reuse the same client id.\n",
    "\n",
    "> Navigate to the [Developer Site](https://developers.globus.org/) and select “Register your app with Globus.” You will be prompted to login – do so with the account you wish to use as your app’s administrator..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifier for the app we created on globus website above, can be reused\n",
    "CLIENT_ID = \"b7f9ff16-4094-4d2a-8183-6dfd9362096a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use fair-research-login to authenticate once with Globus for both FuncX and Globus transfer\n",
    "\n",
    "The first time you have to authenticate, then token is stored in mytokens.json and loaded from there on subsequent calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting login with Globus Auth, press ^C to cancel.\n",
      "Opening in existing browser session.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1476416:1476416:0100/000000.760070:ERROR:sandbox_linux.cc(377)] InitializeSandbox() called with multiple threads in process gpu-process.\n"
     ]
    }
   ],
   "source": [
    "from fair_research_login import NativeClient, JSONTokenStorage\n",
    "\n",
    "cli = NativeClient(\n",
    "    client_id=CLIENT_ID,\n",
    "    token_storage=JSONTokenStorage('mytokens.json'),  # save/load tokens here\n",
    "    app_name=\"FuncX/Globus NeSI Demo\",\n",
    ")\n",
    "\n",
    "# get the requested scopes (load tokens from file if available, otherwise request new tokens)\n",
    "search_scope = \"urn:globus:auth:scope:search.api.globus.org:all\"  # for FuncX\n",
    "funcx_scope = \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\"  # for FuncX\n",
    "openid_scope = \"openid\"  # for FuncX\n",
    "transfer_scope = \"urn:globus:auth:scope:transfer.api.globus.org:all\"  # for Globus transfer client\n",
    "https_scope = f\"https://auth.globus.org/scopes/{nesi_endpoint}/https\"  # for HTTPS upload/download to our guest collection on NeSI\n",
    "tokens = cli.login(\n",
    "    refresh_tokens=True,\n",
    "    requested_scopes=[openid_scope, search_scope, funcx_scope, transfer_scope, https_scope]\n",
    ")\n",
    "\n",
    "# authorisers for requested scopes\n",
    "authorisers = cli.get_authorizers_by_scope(requested_scopes=[openid_scope, funcx_scope, search_scope, transfer_scope, https_scope])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start funcX client locally\n",
    "\n",
    "Start the funcX client locally so we can submit jobs to the NeSI funcX endpoint we just created. This will also require authentication with Globus Auth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcx.sdk.client import FuncXClient\n",
    "\n",
    "fxc = FuncXClient(\n",
    "    fx_authorizer=authorisers[funcx_scope],\n",
    "    search_authorizer=authorisers[search_scope],\n",
    "    openid_authorizer=authorisers[openid_scope],\n",
    ")\n",
    "\n",
    "# create a funcX executor (based on concurrent.futures.Executor)\n",
    "funcx_executor = FuncXExecutor(fxc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test that funcX is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing done? False\n",
      "processing done? True\n",
      "FuncX endpoint is running on: mahuika01\n"
     ]
    }
   ],
   "source": [
    "# test function to see if things are working\n",
    "def test_function():\n",
    "    import socket\n",
    "    return socket.gethostname()\n",
    "\n",
    "# With the executor, functions are auto-registered\n",
    "future = funcx_executor.submit(test_function, endpoint_id=funcx_endpoint)\n",
    "\n",
    "# You can check status of your task without blocking\n",
    "print(\"processing done?\", future.done())\n",
    "\n",
    "# Block and wait for the result:\n",
    "result = future.result()\n",
    "\n",
    "print(\"processing done?\", future.done())\n",
    "\n",
    "print(f\"FuncX endpoint is running on: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Connect to our Globus guest collection on NeSI\n",
    "\n",
    "Connect to the guest collection we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Endpoint activated successfully using Globus Online credentials.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import globus_sdk\n",
    "\n",
    "tc = globus_sdk.TransferClient(authorizer=authorisers[transfer_scope])\n",
    "\n",
    "# activate the NeSI endpoint\n",
    "res_nesi_ep = tc.endpoint_autoactivate(nesi_endpoint)\n",
    "assert res_nesi_ep['code'] != 'AutoActivationFailed'\n",
    "res_nesi_ep[\"message\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setting up HTTPS uploads/downloads for our NeSI guest collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint HTTPS base URL: https://g-51ede9.c61f4.bd7c.data.globus.org\n"
     ]
    }
   ],
   "source": [
    "# get the base URL for uploads and downloads\n",
    "endpoint = tc.get_endpoint(nesi_endpoint)\n",
    "https_server = endpoint['https_server']\n",
    "print(f\"Endpoint HTTPS base URL: {https_server}\")\n",
    "\n",
    "# set up authentication header\n",
    "https_authoriser = authorisers[https_scope]\n",
    "https_auth_header = https_authoriser.get_authorization_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create remote directory using funcX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_remote_directory(base_dir, prefix):\n",
    "    # catch all errors due to problem with exceptions being wrapped in a parsl class,\n",
    "    # requiring parsl to be installed on the local machine\n",
    "    # which is not supported on windows for the version of parsl that funcx-endpoint depends on\n",
    "    try:\n",
    "        import os\n",
    "        import tempfile\n",
    "\n",
    "        remote_dir = tempfile.mkdtemp(prefix=prefix + \"-\", dir=base_dir)\n",
    "        remote_name = os.path.basename(remote_dir)\n",
    "        status = 0\n",
    "\n",
    "    except Exception as exc:\n",
    "        remote_dir = repr(exc)\n",
    "        remote_name = None\n",
    "        status = 1\n",
    "\n",
    "    return status, (remote_dir, remote_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: 0\n",
      "remote directory: /nesi/nobackup/nesi99999/csco212/rjm/funcx-test-20220324T113946-99ybnaa2\n"
     ]
    }
   ],
   "source": [
    "# make a directory for running under\n",
    "from datetime import datetime\n",
    "\n",
    "# get a unique name for this run\n",
    "prefix = datetime.now().strftime(\"funcx-test-%Y%m%dT%H%M%S\")\n",
    "\n",
    "# submit the make directory function to funcx\n",
    "future = funcx_executor.submit(make_remote_directory, nesi_path, prefix, endpoint_id=funcx_endpoint)\n",
    "\n",
    "# wait for the function to complete\n",
    "status, (remote_full_path, remote_dir_name) = future.result()\n",
    "\n",
    "print(f\"status: {status}\")\n",
    "print(f\"remote directory: {remote_full_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Transfer input data to NeSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to upload a file via https to the endpoint\n",
    "def upload_file(local_file, remote_file):\n",
    "    import requests\n",
    "    import time\n",
    "    import os\n",
    "\n",
    "    # file to download and URL\n",
    "    upload_url = f\"{https_server}/{remote_file}\"\n",
    "    print(f\"Uploading: {upload_url}\")\n",
    "\n",
    "    # authorisation\n",
    "    headers = {\n",
    "        \"Authorization\": https_auth_header,\n",
    "    }\n",
    "\n",
    "    # upload\n",
    "    start_time = time.perf_counter()\n",
    "    with open(local_file, 'rb') as f:\n",
    "        r = requests.put(upload_url, data=f, headers=headers)\n",
    "        r.raise_for_status()\n",
    "    upload_time = time.perf_counter() - start_time\n",
    "    file_size = os.path.getsize(local_file)\n",
    "    print(f\"Uploaded {local_file}: {file_size / 1024 / 1024:.3f} MB in {upload_time:.3f} seconds ({file_size / 1024 / 1024 / upload_time:.3f} MB/s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T113946-99ybnaa2/apoa1.pdb\n",
      "Uploaded input/apoa1.pdb: 6.773 MB in 8.118 seconds (0.834 MB/s)\n",
      "Uploading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T113946-99ybnaa2/apoa1.namd\n",
      "Uploaded input/apoa1.namd: 0.001 MB in 3.535 seconds (0.000 MB/s)\n",
      "Uploading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T113946-99ybnaa2/apoa1.psf\n",
      "Uploaded input/apoa1.psf: 12.855 MB in 8.227 seconds (1.563 MB/s)\n",
      "Uploading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T113946-99ybnaa2/par_all22_popc.xplor\n",
      "Uploaded input/par_all22_popc.xplor: 0.000 MB in 2.539 seconds (0.000 MB/s)\n",
      "Uploading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T113946-99ybnaa2/par_all22_prot_lipid.xplor\n",
      "Uploaded input/par_all22_prot_lipid.xplor: 0.149 MB in 2.647 seconds (0.056 MB/s)\n",
      "Uploading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T113946-99ybnaa2/run.sl\n",
      "Uploaded input/run.sl: 0.000 MB in 2.427 seconds (0.000 MB/s)\n",
      "transferring source files to NeSI is complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# get the list of source files\n",
    "src_input_path = \"input\"\n",
    "source_files = [f for f in os.listdir(src_input_path) if os.path.isfile(os.path.join(src_input_path, f))]\n",
    "\n",
    "# transfer the source files\n",
    "for source_file in source_files:\n",
    "    upload_file(os.path.join(src_input_path, source_file), f\"{remote_dir_name}/{source_file}\")\n",
    "\n",
    "print(\"transferring source files to NeSI is complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run the processing using funcX\n",
    "\n",
    "Submit the Slurm job and then wait for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the job to Slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_slurm_job(submit_script, work_dir=None):\n",
    "    \"\"\"Runs the given command in a Slurm job.\"\"\"\n",
    "    # have to load modules within the function\n",
    "    import os\n",
    "    import subprocess\n",
    "    \n",
    "    # change to working directory\n",
    "    if work_dir is not None and os.path.isdir(work_dir):\n",
    "        os.chdir(work_dir)\n",
    "    \n",
    "    # submit the Slurm job and return the job id\n",
    "    submit_cmd = f'sbatch --priority=9999 {submit_script}'\n",
    "    output = subprocess.check_output(submit_cmd, shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job submitted: 25596925\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# With the executor, functions are auto-registered\n",
    "future = funcx_executor.submit(submit_slurm_job, \"run.sl\", endpoint_id=funcx_endpoint, work_dir=remote_full_path)\n",
    "\n",
    "# Block and wait for the result:\n",
    "try:\n",
    "    result = future.result()\n",
    "except subprocess.CalledProcessError as exc:\n",
    "    # allowing exceptions to propagate back to the local machine won't work with windows\n",
    "    print(\"submitting job failed:\")\n",
    "    print(f\"    return code: {exc.returncode}\")\n",
    "    print(f\"    cmd: {exc.cmd}\")\n",
    "    print(f\"    output: {exc.output}\")\n",
    "    raise exc\n",
    "\n",
    "# get the Slurm Job ID\n",
    "jobid = result.split()[-1]\n",
    "print(f\"Job submitted: {jobid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for the job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_slurm_job_status(jobid):\n",
    "    \"\"\"Check Slurm job status.\"\"\"\n",
    "    # have to load modules within the function\n",
    "    import subprocess\n",
    "    \n",
    "    # query the status of the job using sacct\n",
    "    cmd = f'sacct -j {jobid} -X -o State -n'\n",
    "    output = subprocess.check_output(cmd, shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking Slurm job status via funcX: submitting job failed:\n",
      "    return code: 1\n",
      "    cmd: sacct -j 25596925 -X -o State -n\n",
      "    output: sacct: error: slurm_persist_conn_open_without_init: failed to open persistent connection to host:hpcwslurmdb01:6819: Connection refused\n",
      "sacct: error: Sending PersistInit msg: Connection refused\n",
      "sacct: error: Problem talking to the database: Connection refused\n",
      "\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'sacct -j 25596925 -X -o State -n' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    cmd: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;241m.\u001b[39mcmd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m     18\u001b[0m job_status \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(job_status)\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m future \u001b[38;5;241m=\u001b[39m funcx_executor\u001b[38;5;241m.\u001b[39msubmit(check_slurm_job_status, jobid, endpoint_id\u001b[38;5;241m=\u001b[39mfuncx_endpoint)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# allowing exceptions to propagate back to the local machine won't work with windows\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmitting job failed:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'sacct -j 25596925 -X -o State -n' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "job_finished = False\n",
    "while not job_finished:\n",
    "    print(\"checking Slurm job status via funcX: \", end=\"\")\n",
    "    future = funcx_executor.submit(check_slurm_job_status, jobid, endpoint_id=funcx_endpoint)\n",
    "    \n",
    "    try:\n",
    "        result = future.result()\n",
    "    except subprocess.CalledProcessError as exc:\n",
    "        # allowing exceptions to propagate back to the local machine won't work with windows\n",
    "        print(\"submitting job failed:\")\n",
    "        print(f\"    return code: {exc.returncode}\")\n",
    "        print(f\"    cmd: {exc.cmd}\")\n",
    "        print(f\"    output: {exc.output}\")\n",
    "        raise exc\n",
    "    \n",
    "    job_status = result.strip()\n",
    "    print(job_status)\n",
    "    if job_status not in (\"RUNNING\", \"PENDING\"):\n",
    "        job_finished = True\n",
    "    time.sleep(5)\n",
    "print(\"Job finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Copy results back using Globus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download a file via https from the endpoint\n",
    "def download_file(remote_file, local_file):\n",
    "    import requests\n",
    "    import time\n",
    "    import os\n",
    "\n",
    "    # file to download and URL\n",
    "    download_url = f\"{https_server}/{remote_file}\"\n",
    "    print(f\"Downloading: {download_url}\")\n",
    "\n",
    "    # authorisation header\n",
    "    headers = {\n",
    "        \"Authorization\": https_auth_header,\n",
    "    }\n",
    "\n",
    "    # download\n",
    "    start_time = time.perf_counter()\n",
    "    with requests.get(download_url, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_file, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    download_time = time.perf_counter() - start_time\n",
    "    file_size = os.path.getsize(local_file)\n",
    "    print(f\"Downloaded {local_file}: {file_size / 1024 / 1024:.3f} MB in {download_time:.3f} seconds ({file_size / 1024 / 1024 / download_time:.3f} MB/s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T110820-q1t724b0/apoa1.namd\n",
      "Downloaded output/funcx-test-20220324T110820-q1t724b0/apoa1.namd: 0.001 MB in 5.167 seconds (0.000 MB/s)\n",
      "Downloading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T110820-q1t724b0/apoa1.pdb\n",
      "Downloaded output/funcx-test-20220324T110820-q1t724b0/apoa1.pdb: 6.773 MB in 3.464 seconds (1.955 MB/s)\n",
      "Downloading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T110820-q1t724b0/apoa1.psf\n",
      "Downloaded output/funcx-test-20220324T110820-q1t724b0/apoa1.psf: 12.855 MB in 7.582 seconds (1.696 MB/s)\n",
      "Downloading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T110820-q1t724b0/par_all22_popc.xplor\n",
      "Downloaded output/funcx-test-20220324T110820-q1t724b0/par_all22_popc.xplor: 0.000 MB in 5.450 seconds (0.000 MB/s)\n",
      "Downloading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T110820-q1t724b0/par_all22_prot_lipid.xplor\n",
      "Downloaded output/funcx-test-20220324T110820-q1t724b0/par_all22_prot_lipid.xplor: 0.149 MB in 4.354 seconds (0.034 MB/s)\n",
      "Downloading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T110820-q1t724b0/run.sl\n",
      "Downloaded output/funcx-test-20220324T110820-q1t724b0/run.sl: 0.000 MB in 3.200 seconds (0.000 MB/s)\n",
      "Downloading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T110820-q1t724b0/slurm-25596866.out\n",
      "Downloaded output/funcx-test-20220324T110820-q1t724b0/slurm-25596866.out: 0.026 MB in 2.842 seconds (0.009 MB/s)\n",
      "Downloading: https://g-51ede9.c61f4.bd7c.data.globus.org/funcx-test-20220324T110820-q1t724b0/submit_cmd.txt\n",
      "Downloaded output/funcx-test-20220324T110820-q1t724b0/submit_cmd.txt: 0.000 MB in 2.617 seconds (0.000 MB/s)\n",
      "transferring results from NeSI is complete: output/funcx-test-20220324T110820-q1t724b0\n"
     ]
    }
   ],
   "source": [
    "# create directory for storing result\n",
    "store_path = os.path.join(\"output\", remote_dir_name)\n",
    "os.mkdir(store_path)\n",
    "\n",
    "# list and download files\n",
    "ls = tc.operation_ls(nesi_endpoint, path=remote_dir_name)\n",
    "for item in ls:\n",
    "    if item[\"type\"] == \"file\":\n",
    "        fn = item[\"name\"]\n",
    "        download_file(f\"{remote_dir_name}/{fn}\", os.path.join(store_path, fn))\n",
    "    else:\n",
    "        print(f\"Skipping: {item['name']} (can only download files over HTTPS)\")\n",
    "\n",
    "print(f\"transferring results from NeSI is complete: {store_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes about FuncX and Globus HTTPS\n",
    "\n",
    "* this example mostly uses FuncX as a Slurm API - can be used for much more than that\n",
    "* fair_research_login is a nice interface to globus auth\n",
    "* guest collection HTTPS access convenient because it doesn't need a personal endpoint running on the local machine\n",
    "* Guest collections can be accessed with just Globus auth, no need for NeSI 2 factor auth after initially creating the guest collection\n",
    "* any user can set up and use funcX by themself - they don't need us to do anything to enable it\n",
    "* researcher needs to manually run a funcx endpoint on NeSI (and keep it running there)\n",
    "  - eventually could be integrated with Globus federated endpoint?\n",
    "  - could be a pain if the endpoint is killed for some reason and the user needs to reconnect and start it again (e.g. login node gets rebooted)\n",
    "    * have a bash script running as a scrontab currently\n",
    "* (THIS EXAMPLE NEEDS UPDATING) FuncX does know about Slurm too, so you could set FuncX up to directly run your function in a Slurm job without having to submit anything separately, see snippet from an endpoint config.py:\n",
    "  ```sh\n",
    "    from funcx_endpoint.endpoint.utils.config import Config\n",
    "    from parsl.providers import LocalProvider, SlurmProvider\n",
    "\n",
    "    config = Config(\n",
    "        scaling_enabled=True,\n",
    "        provider=SlurmProvider(\n",
    "            \"large\",\n",
    "            min_blocks=1,\n",
    "            max_blocks=1,\n",
    "            nodes_per_block=1,\n",
    "            cores_per_node=2,\n",
    "            mem_per_node=16,\n",
    "            exclusive=False,\n",
    "            cmd_timeout=120,\n",
    "            walltime='2:00:00',\n",
    "        ),\n",
    "        #max_workers_per_node=2,\n",
    "        funcx_service_address='https://api.funcx.org/v1'\n",
    "    )\n",
    "  ```\n",
    "* reasons for not using FuncX SlurmProvider directly currently\n",
    "  - funcx currently has no way to know how much work a function may involve\n",
    "    - could lead to failures due to wall time exceeded, etc.\n",
    "  - not \"elastic\"\n",
    "    - have to start a new endpoint if need resources\n",
    "  - submitting and checking slurm jobs is something that can run on a login node, no need for more in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
