{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globus and Funcx \n",
    "\n",
    "Using Globus and Funcx to automate the process of uploading data to NeSI, running something on NeSI and then copying results back.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* Globus account\n",
    "* Globus personal endpoint running on the machine you are executing this notebook\n",
    "* NeSI account, username and 2nd factor, for authenticating with the NeSI Globus endpoint and running a Funcx endpoint\n",
    "\n",
    "Authentication/setup Steps:\n",
    "\n",
    "1. Connect to NeSI cluster and start a funcx endpoint there\n",
    "2. Globus authentication (including FuncX) on local machine\n",
    "3. Start funcX client locally\n",
    "4. Create Globus transfer client\n",
    "5. Connect to source Globus endpoint\n",
    "6. Connect to NeSI Globus endpoint\n",
    "\n",
    "Processing Steps:\n",
    "\n",
    "7. Transfer input data to NeSI using Globus\n",
    "8. Run the workflow using funcX\n",
    "9. Copy result back using Globus\n",
    "\n",
    "Steps 1,2 and 6 above require authentication. \n",
    "\n",
    "The tokens generated in step 2 on the local machine are stored in a file and reused, so you should only need to authenticate the first time.\n",
    "\n",
    "Connecting to NeSI Globus endpoint in step 6 requires NeSI 2 factor authentication and you only remain authenticated for ~24 hours.\n",
    "\n",
    "References:\n",
    "\n",
    "* [Globus tutorial](https://globus-sdk-python.readthedocs.io/en/stable/tutorial.html)\n",
    "* [funcX endpoint documentation](https://funcx.readthedocs.io/en/latest/endpoints.html)\n",
    "* [fair-research-login](https://github.com/fair-research/native-login)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Start funcx endpoint on NeSI\n",
    "\n",
    "### Install and configure funcx endpoint if you have not done it before\n",
    "\n",
    "Connect to a Mahuika login node by SSH and run the following commands to install funcx:\n",
    "\n",
    "```sh\n",
    "ssh mahuika\n",
    "module load Python\n",
    "pip install --user funcx funcx_endpoint fair-research-login\n",
    "funcx-endpoint configure\n",
    "```\n",
    "\n",
    "During the final command you will be asked to authenticate with Globus Auth so that your endpoint can be made available to funcx running outside of NeSI.\n",
    "\n",
    "For more details see: https://funcx.readthedocs.io/en/latest/endpoints.html.\n",
    "\n",
    "### Start the funcx endpoint on NeSI\n",
    "\n",
    "A default endpoint profile is created during the configure step above, which will suffice for us. We will be using funcx to submit jobs to Slurm or check the status of submitted jobs; no computationally expensive tasks should run directly on the endpoint itself.\n",
    "\n",
    "```sh\n",
    "# we are still on the Mahuika login node here...\n",
    "funcx-endpoint start\n",
    "```\n",
    "\n",
    "Now list your endpoints, confirm that the *default* endpoint is \"Active\" and make a note of your endpoint ID:\n",
    "\n",
    "```sh\n",
    "funcx-endpoint list\n",
    "+---------------+-------------+--------------------------------------+\n",
    "| Endpoint Name |   Status    |             Endpoint ID              |\n",
    "+===============+=============+======================================+\n",
    "| default       | Active      | f9058e4c-3b93-46a9-a764-81810c86c2b3 |\n",
    "+---------------+-------------+--------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store your funcx endpoint id here\n",
    "funcx_endpoint = \"f9058e4c-3b93-46a9-a764-81810c86c2b3\"  # my default endpoint on NeSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Globus authentication (including FuncX) on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register an app with Globus, if you haven't done it already\n",
    "\n",
    "Note: I think this is a one off, you can reuse the same client id.\n",
    "\n",
    "> Navigate to the [Developer Site](https://developers.globus.org/) and select “Register your app with Globus.” You will be prompted to login – do so with the account you wish to use as your app’s administrator..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifier for the app we created on globus website above, can be reused\n",
    "CLIENT_ID = \"6ffc9c02-cf62-4268-a695-d9d100181962\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use fair-research-login to authenticate once with Globus for both FuncX and Globus transfer\n",
    "\n",
    "The first time you have to authenticate, then token is stored in mytokens.json and loaded from there on subsequent calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fair_research_login import NativeClient, JSONTokenStorage\n",
    "\n",
    "cli = NativeClient(\n",
    "    client_id=CLIENT_ID,\n",
    "    token_storage=JSONTokenStorage('mytokens.json'),  # save/load tokens here\n",
    "    app_name=\"FuncX/Globus NeSI Demo\",\n",
    ")\n",
    "\n",
    "# get the requested scopes\n",
    "search_scope = \"urn:globus:auth:scope:search.api.globus.org:all\"  # for FuncX\n",
    "funcx_scope = \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\"  # for FuncX\n",
    "openid_scope = \"openid\"  # for FuncX\n",
    "transfer_scope = \"urn:globus:auth:scope:transfer.api.globus.org:all\"  # for Globus transfer\n",
    "tokens = cli.login(\n",
    "    refresh_tokens=True,\n",
    "    requested_scopes=[openid_scope, search_scope, funcx_scope, transfer_scope]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorisers for requested scopes\n",
    "authorisers = cli.get_authorizers_by_scope(requested_scopes=[openid_scope, funcx_scope, search_scope, transfer_scope])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Start funcX client locally\n",
    "\n",
    "Start the funcX client locally so we can submit jobs to the NeSI funcX endpoint we just created. This will also require authentication with Globus Auth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcx.sdk.client import FuncXClient\n",
    "\n",
    "fxc = FuncXClient(\n",
    "    fx_authorizer=authorisers[funcx_scope],\n",
    "    search_authorizer=authorisers[search_scope],\n",
    "    openid_authorizer=authorisers[openid_scope],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Globus transfer client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globus_sdk\n",
    "\n",
    "tc = globus_sdk.TransferClient(authorizer=authorisers[transfer_scope])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Globus Endpoints:\n",
      "  - [6890f1a4-3f21-11eb-b55a-02d9497ca481] cdjs-desktop\n",
      "  - [1fdfb7aa-544e-11eb-87b7-02187389bd35] WorkLaptop\n"
     ]
    }
   ],
   "source": [
    "print(\"My Globus Endpoints:\")\n",
    "for ep in tc.endpoint_search(filter_scope=\"my-endpoints\"):\n",
    "    print(\"  - [{}] {}\".format(ep[\"id\"], ep[\"display_name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Connect to source Globus endpoint\n",
    "\n",
    "Connect to the personal endpoint you have on your local machine (e.g. where you are running this notebook).\n",
    "\n",
    "You should not need to do any authentication since Globus will use the token you generated above.\n",
    "\n",
    "We list the files in the input data directory to check our access is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint activation succeeded: AutoActivated.GlobusOnlineCredential\n",
      "Source files:\n",
      "  apoa1.namd (file)\n",
      "  apoa1.pdb (file)\n",
      "  apoa1.psf (file)\n",
      "  par_all22_popc.xplor (file)\n",
      "  par_all22_prot_lipid.xplor (file)\n",
      "  run.sl (file)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# put your Globus endpoint id here:\n",
    "#src_endpoint = \"1fdfb7aa-544e-11eb-87b7-02187389bd35\"\n",
    "src_endpoint = \"6890f1a4-3f21-11eb-b55a-02d9497ca481\"\n",
    "\n",
    "# paths to input and output\n",
    "src_base_path = os.getcwd()\n",
    "src_input_path = os.path.join(src_base_path, \"input\")\n",
    "src_output_path = os.path.join(src_base_path, \"output\")\n",
    "\n",
    "# activate the endpoint\n",
    "res_src_ep = tc.endpoint_autoactivate(src_endpoint, if_expires_in=3600)\n",
    "if res_src_ep['code'] == 'AutoActivationFailed':\n",
    "    print(\"Endpoint activation failed!\")\n",
    "    print(res_src_ep)\n",
    "else:\n",
    "    print(f\"Endpoint activation succeeded: {res_src_ep['code']}\")\n",
    "    \n",
    "    # list the source directory\n",
    "    print(\"Source files:\")\n",
    "    for entry in tc.operation_ls(src_endpoint, path=src_input_path):\n",
    "        print(f'  {entry[\"name\"]} ({entry[\"type\"]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Connect to the NeSI Globus endpoint\n",
    "\n",
    "Authentication to the NeSI endpoint is more complicated. In addition to the Globus token we also need to authenticate with our NeSI username, password and 2nd factor. You will be prompted to enter these below.\n",
    "\n",
    "Authentication to the NeSI endpoint lasts for 1-2 days, i.e. you will not need to reenter your NeSI credentials every time you use the NeSI endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nesi_endpoint = \"3064bb28-e940-11e8-8caa-0a1d4c5c824a\"  # NeSI endpoint\n",
    "nesi_path = \"/nesi/nobackup/nesi99999/csco212/cer_instrument_data/funcx/test-workflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing authentication we have to deactivate first...\n",
    "#tc.endpoint_deactivate(nesi_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The endpoint could not be auto activated, fill in the returned activation_requirements and POST them back to /activate to perform manual activation.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# activate the endpoint\n",
    "res_nesi_ep = tc.endpoint_autoactivate(nesi_endpoint, if_expires_in=3600)\n",
    "res_nesi_ep[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint activation failed!\n",
      "The endpoint could not be auto activated, fill in the returned activation_requirements and POST them back to /activate to perform manual activation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter NeSI username:  csco212\n",
      "Enter NeSI password and 2nd factor joined together:  ···················\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated.MyProxyCredential\n",
      "Endpoint activated successfully using a credential fetched from a MyProxy server.\n"
     ]
    }
   ],
   "source": [
    "# if auto activation failed, try activate\n",
    "if res_nesi_ep['code'] == 'AutoActivationFailed':\n",
    "    print(\"Endpoint activation failed!\")\n",
    "    print(res_nesi_ep[\"message\"])\n",
    "    #print(res_nesi_ep)\n",
    "    \n",
    "    # try normal activate, first get username and password\n",
    "    import getpass\n",
    "    nesi_user = input(\"Enter NeSI username: \").strip()\n",
    "    nesi_pass = getpass.getpass(prompt=\"Enter NeSI password and 2nd factor joined together: \")\n",
    "\n",
    "    # then get requirements and fill in user/pass\n",
    "    req = tc.endpoint_get_activation_requirements(nesi_endpoint)\n",
    "    rd = req.data\n",
    "    for i in range(rd[\"length\"]):\n",
    "        name = rd[\"DATA\"][i][\"name\"]\n",
    "        if name == \"username\":\n",
    "            rd[\"DATA\"][i][\"value\"] = nesi_user\n",
    "        elif name == \"passphrase\":\n",
    "            rd[\"DATA\"][i][\"value\"] = nesi_pass\n",
    "\n",
    "    # activate\n",
    "    res_nesi_ep = tc.endpoint_activate(nesi_endpoint, rd, if_expires_in=3600)\n",
    "    print(res_nesi_ep[\"code\"])\n",
    "    print(res_nesi_ep[\"message\"])\n",
    "    \n",
    "else:\n",
    "    print(f\"Endpoint activation succeeded: {res_dst_ep['code']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transfer input data to NeSI\n",
    "\n",
    "First we make a directory name that the simulation will be stored under, then copy the data under that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: 20210407T142348\n"
     ]
    }
   ],
   "source": [
    "# make a directory for running under\n",
    "from datetime import datetime\n",
    "\n",
    "# get a unique name for this run\n",
    "workdirbase = datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "workdirname = workdirbase\n",
    "got_dirname = False\n",
    "existing_names = [item[\"name\"] for item in tc.operation_ls(nesi_endpoint, path=nesi_path)]\n",
    "count = 0\n",
    "while not got_dirname:\n",
    "    # check the directory does not already exist\n",
    "    if workdirname in existing_names:\n",
    "        count += 1\n",
    "        workdirname = f\"{workdirbase}.{count:06d}\"\n",
    "    else:\n",
    "        got_dirname = True\n",
    "print(f\"Directory: {workdirname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory on NeSI will be: /nesi/nobackup/nesi99999/csco212/cer_instrument_data/funcx/test-workflow/20210407T142348\n",
      "task_id = 4fd6432e-9748-11eb-955b-752ba7b88ebe\n",
      "waiting for transfer to complete...\n",
      "waiting for transfer to complete...\n",
      "waiting for transfer to complete...\n",
      "waiting for transfer to complete...\n",
      "transfer to NeSI is complete\n"
     ]
    }
   ],
   "source": [
    "# initiate the data transfer to NeSI\n",
    "tdata = globus_sdk.TransferData(tc, src_endpoint,\n",
    "                                    nesi_endpoint,\n",
    "                                    label=\"Copying input data\",\n",
    "                                    sync_level=\"checksum\")\n",
    "\n",
    "# add the input files to the transfer\n",
    "nesi_work_path = nesi_path + \"/\" + workdirname\n",
    "print(f\"Working directory on NeSI will be: {nesi_work_path}\")\n",
    "tdata.add_item(src_input_path, nesi_work_path,\n",
    "               recursive=True)\n",
    "\n",
    "# actually start the transfer\n",
    "transfer_result = tc.submit_transfer(tdata)\n",
    "task_id = transfer_result[\"task_id\"]\n",
    "print(\"task_id =\", transfer_result[\"task_id\"])\n",
    "\n",
    "# the task id can be used to refer to this transfer\n",
    "# for example, here we wait for the data transfer to complete\n",
    "while not tc.task_wait(task_id, timeout=10, polling_interval=10):\n",
    "    print(\"waiting for transfer to complete...\")\n",
    "print(\"transfer to NeSI is complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also login to Globus web interface and see the status of your transfer there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run the processing using funcX\n",
    "\n",
    "Two functions are called using FuncX:\n",
    "\n",
    "1. Submit job to Slurm\n",
    "2. Check Slurm job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FuncX endpoint id: f9058e4c-3b93-46a9-a764-81810c86c2b3\n"
     ]
    }
   ],
   "source": [
    "print(f\"FuncX endpoint id: {funcx_endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2268de74-e44d-4a45-af43-4b1634b63a31'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that submits a job to Slurm (assumes submit script and other required inputs were uploaded via Globus)\n",
    "def run_processing(submit_script, work_dir=None):\n",
    "    \"\"\"Runs the given command in a Slurm job.\"\"\"\n",
    "    # have to load modules within the function\n",
    "    import os\n",
    "    import subprocess\n",
    "    \n",
    "    # change to working directory\n",
    "    if work_dir is not None and os.path.isdir(work_dir):\n",
    "        os.chdir(work_dir)\n",
    "    \n",
    "    # submit the Slurm job and return the job id\n",
    "    submit_cmd = f'sbatch --priority=9999 {submit_script}'\n",
    "    with open(\"submit_cmd.txt\", \"w\") as fh:\n",
    "        fh.write(submit_cmd + \"\\n\")\n",
    "    output = subprocess.check_output(submit_cmd, shell=True, universal_newlines=True)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# register the function with FuncX - we have to do this so that we can execute the function on our remote endpoint\n",
    "processing_func_id = fxc.register_function(run_processing)\n",
    "processing_func_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'78301134-0873-47b5-b7af-8bf82a6f3ae0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that checks Slurm job status\n",
    "def check_status(jobid):\n",
    "    \"\"\"Check Slurm job status.\"\"\"\n",
    "    # have to load modules within the function\n",
    "    import subprocess\n",
    "    \n",
    "    # submit the Slurm job and return the job id\n",
    "    cmd = f'sacct -j {jobid} -X -o State -n'\n",
    "    output = subprocess.check_output(cmd, shell=True, universal_newlines=True)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# register the function with FuncX - we have to do this so that we can execute the function on our remote endpoint\n",
    "status_func_id = fxc.register_function(check_status)\n",
    "status_func_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the job to Slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funcX result id: 3ec87a65-8cf1-48cf-b6aa-94b9a3d88daa\n",
      "submitting job via funcX:\n",
      "waiting-for-ep\n",
      "Job submitted: 18943944\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "resid = fxc.run(\"run.sl\", work_dir=nesi_work_path, endpoint_id=funcx_endpoint, function_id=processing_func_id)\n",
    "print(f\"funcX result id: {resid}\")\n",
    "\n",
    "# wait for the job to run\n",
    "print(\"submitting job via funcX:\")\n",
    "while True:\n",
    "    try:\n",
    "        res = fxc.get_result(resid)\n",
    "    except Exception as e:\n",
    "        stre = str(e)\n",
    "        if stre in [\"waiting-for-ep\", \"waiting-for-launch\", \"running\"]:  # these are \"good\" exceptions \n",
    "            print(stre)\n",
    "            time.sleep(10)\n",
    "        else: \n",
    "            raise  # other exceptions mean something went wrong\n",
    "    else:\n",
    "        break  # no exception means the job finished successfully\n",
    "\n",
    "jobid = res.split()[-1]\n",
    "print(f\"Job submitted: {jobid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for the job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submitting status job via funcX:\n",
      "Job status is: COMPLETED\n",
      "Job finished\n"
     ]
    }
   ],
   "source": [
    "job_finished = False\n",
    "while not job_finished:\n",
    "    resid = fxc.run(jobid, endpoint_id=funcx_endpoint, function_id=status_func_id)\n",
    "    print(\"submitting status job via funcX:\")\n",
    "    while True:\n",
    "        try:\n",
    "            res = fxc.get_result(resid)\n",
    "        except Exception as e:\n",
    "            stre = str(e)\n",
    "            if stre in [\"waiting-for-ep\", \"waiting-for-launch\", \"running\"]:  # these are \"good\" exceptions \n",
    "                print(stre)\n",
    "                time.sleep(10)\n",
    "            else: \n",
    "                raise  # other exceptions mean something went wrong\n",
    "        else:\n",
    "            break  # no exception means the job finished successfully\n",
    "    job_status = res.strip()\n",
    "    print(f\"Job status is: {job_status}\")\n",
    "    if job_status not in (\"RUNNING\", \"PENDING\"):  # TODO: check possible statuses\n",
    "        job_finished = True\n",
    "print(\"Job finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Copy result back using Globus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id = c98e3294-9748-11eb-b7a9-f57b2d55370d\n",
      "waiting for transfer to complete...\n",
      "waiting for transfer to complete...\n",
      "waiting for transfer to complete...\n",
      "waiting for transfer to complete...\n",
      "transfer from NeSI is complete: /home/cdjs/DocumentsSync/work/projects/cer_instrument_data/funcx/funcx-globus-nesi-demo/output/20210407T142348\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from_path = nesi_work_path\n",
    "to_path = os.path.join(src_output_path, workdirname)\n",
    "tdata = globus_sdk.TransferData(tc, nesi_endpoint,\n",
    "                                    src_endpoint,\n",
    "                                    label=\"Copying results\",\n",
    "                                    sync_level=\"checksum\")\n",
    "tdata.add_item(from_path, to_path, recursive=True)\n",
    "transfer_result = tc.submit_transfer(tdata)\n",
    "task_id = transfer_result[\"task_id\"]\n",
    "print(\"task_id =\", transfer_result[\"task_id\"])\n",
    "\n",
    "# wait for the data transfer to complete\n",
    "while not tc.task_wait(task_id, timeout=10, polling_interval=10):\n",
    "    print(\"waiting for transfer to complete...\")\n",
    "print(f\"transfer from NeSI is complete: {to_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes about FuncX so far\n",
    "\n",
    "* above uses FuncX just to submit a Slurm job and then poll for completion (could also be done with Slurm API)\n",
    "* researcher needs to manually run a funcx endpoint on NeSI (and keep it running there)\n",
    "  - eventually should be integrated with Globus federated endpoint\n",
    "* FuncX does know about Slurm too, so you could set FuncX up to directly run your function in a Slurm job without having to submit anything separately, see snippet from an endpoint config.py:\n",
    "  ```sh\n",
    "    from funcx_endpoint.endpoint.utils.config import Config\n",
    "    from parsl.providers import LocalProvider, SlurmProvider\n",
    "\n",
    "    config = Config(\n",
    "        scaling_enabled=True,\n",
    "        provider=SlurmProvider(\n",
    "            \"large\",\n",
    "            min_blocks=1,\n",
    "            max_blocks=1,\n",
    "            nodes_per_block=1,\n",
    "            cores_per_node=2,\n",
    "            mem_per_node=16,\n",
    "            exclusive=False,\n",
    "            cmd_timeout=120,\n",
    "            walltime='2:00:00',\n",
    "        ),\n",
    "        #max_workers_per_node=2,\n",
    "        funcx_service_address='https://api.funcx.org/v1'\n",
    "    )\n",
    "  ```\n",
    "* reasons for not using FuncX SlurmProvider directly currently\n",
    "  - funcx currently has no way to know how much work a function may involve\n",
    "    - could lead to failures due to wall time exceeded, etc.\n",
    "  - not \"elastic\"\n",
    "    - have to start a new endpoint if need more resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
